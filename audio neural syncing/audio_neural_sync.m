% Sync audio and neural data. TTL pulses embedded in silent sound files
% (generated by my code, generate_silent_playback_files_with_TTL_pulses.m)
% were sent to both the Avisoft recorder and the Neurologger, and the
% common times of the pulses are used for syncing. 1/5/2017 Wujie Zhang
%%
session_folder='H:\Wujie\Data\two bat recording 1\20170305\communication\';

TTL_pulse_step_tolerance_ms=1.1; % if the difference between consecutive neural pulses is different from what it's supposed to be by more than this much, consider it an error
audio_neural_pulse_match_tolerance_ms=1.5; % an audio TTL pulse and a neural TTL pulse are identified as the same pulse only if the difference between their durations is less than this
Avisoft_sampling_freq=250000;
TTL_playback_files_parameter_file='F:\Wujie\Data\Misc\TTL playback files 20161219\20161219_TTL_playback_files_paramters_and_details.mat';

% bats_number_name={'bat71348_WH' 'bat65997_TD'};
bats_number_name={'bat59813_YL' 'bat60141_TC'}; % no need to change this each session--the code automatically detects which of the bats were in the session
%%
neural_event_folders={fullfile(session_folder,bats_number_name{1},'neural') fullfile(session_folder,bats_number_name{2},'neural')};
audio_folder=fullfile(session_folder,'audio','ch1');

sync_save_file_name=fullfile(session_folder,'audio_neural_video_sync.mat');
load(TTL_playback_files_parameter_file)
%%
% Find the audio TTL pulses
recorded_file_list=dir(fullfile(audio_folder,'*.wav')); % all the .wav files in the folder; '.wav' here is not case-sensitive
name_list={recorded_file_list.name}';
name_list=cell2mat(name_list);
name_list=num2cell(name_list(:,end-10:end-4),2);
[~,name_order]=sort(name_list);
recorded_file_list=recorded_file_list(name_order);

num_samples_searched=0;
indices_pre_falling=[];
indices_pre_rising=[];
last_sample=nan;
indices_of_first_audio_samples=zeros(length(recorded_file_list),1); % the indices of the first sample of each audio file, counting from the start of the first audio file
num_audio_samples_by_end_of_each_file=zeros(length(recorded_file_list),1); % counting from the start of the first audio file
for file_i=1:length(recorded_file_list)
    indices_of_first_audio_samples(file_i)=num_samples_searched+1;
    
    [audio_samples_int16,~]=audioread(fullfile(audio_folder,recorded_file_list(file_i).name),'native');
    TTL_states=bitget(audio_samples_int16,1,'int16');
    
    indices_pre_falling_current_file=find(diff(TTL_states)==-1); % each element is the index of a sample before a falling edge
    indices_pre_rising_current_file=find(diff(TTL_states)==1); % each element is the index of a sample before a rising edge
    if TTL_states(1)-last_sample==-1
        indices_pre_falling=[indices_pre_falling; num_samples_searched]; %#ok<*AGROW>
    elseif TTL_states(1)-last_sample==1
        indices_pre_rising=[indices_pre_rising; num_samples_searched];
    end
    indices_pre_falling=[indices_pre_falling; num_samples_searched+indices_pre_falling_current_file];
    indices_pre_rising=[indices_pre_rising; num_samples_searched+indices_pre_rising_current_file];
    last_sample=TTL_states(end);
    num_samples_searched=num_samples_searched+length(TTL_states);
    
    num_audio_samples_by_end_of_each_file(file_i)=num_samples_searched;
end
indices_post_falling=indices_pre_falling+1;
indices_post_rising=indices_pre_rising+1;

audio_fall_times_ms=indices_post_falling/Avisoft_sampling_freq*1000;
audio_rise_times_ms=indices_post_rising/Avisoft_sampling_freq*1000;
if length(audio_fall_times_ms)==length(audio_rise_times_ms)+1
    audio_fall_times_ms=audio_fall_times_ms(1:end-1);
elseif length(audio_fall_times_ms)+1==length(audio_rise_times_ms)
    audio_rise_times_ms=audio_rise_times_ms(2:end);
elseif length(audio_fall_times_ms)==length(audio_rise_times_ms) && audio_fall_times_ms(1)>audio_rise_times_ms(1)
    audio_fall_times_ms=audio_fall_times_ms(1:end-1);
    audio_rise_times_ms=audio_rise_times_ms(2:end);
end
audio_TTL_durations_ms=audio_rise_times_ms-audio_fall_times_ms;

to_delete=false(length(neural_event_folders),1);
for check_folder_i=1:length(neural_event_folders)
    if ~exist(neural_event_folders{check_folder_i},'dir')
        to_delete(check_folder_i)=true;
    end
end
neural_event_folders(to_delete)=[];
bats_number_name(to_delete)=[];

all_pulses_fig=cell(length(neural_event_folders));
rounding_fig=cell(length(neural_event_folders));

for logger_i=1:length(neural_event_folders)
    all_pulses_fig{logger_i}=figure;
    subplot(1,2,1)
    plot((audio_fall_times_ms-audio_fall_times_ms(1))/(1000*60),audio_TTL_durations_ms,'bo')
end

to_delete=false(size(audio_TTL_durations_ms));
for pulse_i=2:length(audio_TTL_durations_ms)-1
    if abs((audio_TTL_durations_ms(pulse_i)-audio_TTL_durations_ms(pulse_i-1))-TTL_pulse_duration_unit_ms)>TTL_pulse_step_tolerance_ms && abs((audio_TTL_durations_ms(pulse_i+1)-audio_TTL_durations_ms(pulse_i))-TTL_pulse_duration_unit_ms)>TTL_pulse_step_tolerance_ms
        to_delete(pulse_i)=true;
    end
end

audio_fall_times_ms(to_delete)=[];
audio_rise_times_ms(to_delete)=[];
audio_TTL_durations_ms(to_delete)=[];
if any(to_delete)
    disp(['Deleted ' num2str(sum(to_delete)) ' audio pulses with incorrect durations...'])
end

for logger_i=1:length(neural_event_folders)
    figure(all_pulses_fig{logger_i})
    subplot(1,2,1)
    hold on
    plot((audio_fall_times_ms-audio_fall_times_ms(1))/(1000*60),audio_TTL_durations_ms,'ko')
    xlabel('Time since first audio TTL pulse (minute)')
    ylabel('Pulse duration (ms)')
    title('Audio TTL pulses')
    
    rounding_fig{logger_i}=figure;
    subplot(1,2,1)
    plot(audio_TTL_durations_ms-round(audio_TTL_durations_ms),'o')
    xlabel('Audio TTL pulse number')
    ylabel('Pulse duration difference from nearest integer (ms)')
    title('Audio TTL pulses')
    % Check this every time: the differences should start around zero, and
    % change roughly linearly and monotonically to 0.5 or -0.5, which indicates
    % that they would still be rounded to the correct duration, which is fine.
end
%%
audio_sync_times_ms_from_beginning=cell(length(neural_event_folders),1);
neural_sync_with_audio_times_ms_from_midnight=cell(length(neural_event_folders),1);
for logger_i=1:length(neural_event_folders)
    %%
    % Find the neural TTL pulses
    load(fullfile(neural_event_folders{logger_i},'EVENTS.mat'))
    
    logical_indices_TTL_events=~cellfun(@isempty,strfind(event_types_and_details,'Digital in'));
    TTL_event_timestamps_msec=event_timestamps_usec(logical_indices_TTL_events)/1000; % convert to ms, without rounding to integer ms
    TTL_event_types_and_details=event_types_and_details(logical_indices_TTL_events);
    
    % loop over all event strings and find corresponding falling/rising edges
    % and their timestamps; note that a single TTL pulse begins with a
    % falling edge
    num_TTL_events=length(TTL_event_types_and_details);
    TTL_pulse_counter=0;
    neural_fall_times_ms=nan(num_TTL_events,1);
    neural_rise_times_ms=nan(num_TTL_events,1);
    neural_TTL_durations_ms=nan(num_TTL_events,1);
    for TTL_event_i=1:num_TTL_events-1 % only go til the next-to-last event, because if the last event is a falling edge, it's not useful
        if any(strfind(TTL_event_types_and_details{TTL_event_i},'falling')) && any(strfind(TTL_event_types_and_details{TTL_event_i+1},'rising'))
            TTL_pulse_counter=TTL_pulse_counter+1;
            neural_fall_times_ms(TTL_pulse_counter)=TTL_event_timestamps_msec(TTL_event_i);
            neural_rise_times_ms(TTL_pulse_counter)=TTL_event_timestamps_msec(TTL_event_i+1);
            neural_TTL_durations_ms(TTL_pulse_counter)=neural_rise_times_ms(TTL_pulse_counter)-neural_fall_times_ms(TTL_pulse_counter);
        end
    end
    neural_fall_times_ms(isnan(neural_fall_times_ms))=[];
    neural_rise_times_ms(isnan(neural_rise_times_ms))=[];
    neural_TTL_durations_ms(isnan(neural_TTL_durations_ms))=[];
    
    figure(all_pulses_fig{logger_i})
    subplot(1,2,2)
    plot((neural_fall_times_ms-neural_fall_times_ms(1))/(1000*60),neural_TTL_durations_ms,'bo')
    
    to_delete=false(size(neural_TTL_durations_ms));
    for pulse_i=2:length(neural_TTL_durations_ms)-1 % for each neural pulse, check intervals between it and the previous pulse and between it and the following pulse, and delete the pulse if both intervals are wrong
        if abs((neural_TTL_durations_ms(pulse_i)-neural_TTL_durations_ms(pulse_i-1))-TTL_pulse_duration_unit_ms)>TTL_pulse_step_tolerance_ms && abs((neural_TTL_durations_ms(pulse_i+1)-neural_TTL_durations_ms(pulse_i))-TTL_pulse_duration_unit_ms)>TTL_pulse_step_tolerance_ms
            to_delete(pulse_i)=true;
        end
    end
    
    neural_fall_times_ms(to_delete)=[];
    neural_rise_times_ms(to_delete)=[];
    neural_TTL_durations_ms(to_delete)=[];
    if any(to_delete)
        disp(['Deleted ' num2str(sum(to_delete)) ' neural pulses with incorrect durations...'])
    end
    
    hold on
    plot((neural_fall_times_ms-neural_fall_times_ms(1))/(1000*60),neural_TTL_durations_ms,'ko')
    xlabel('Time since first neural TTL pulse (minute)')
    ylabel('Pulse duration (ms)')
    title(['Neural TTL pulses, ' bats_number_name{logger_i}],'Interpreter','none')
    
    figure(rounding_fig{logger_i})
    subplot(1,2,2)
    plot(neural_TTL_durations_ms-round(neural_TTL_durations_ms),'o')
    xlabel('Neural TTL pulse number')
    ylabel('Pulse duration difference from nearest integer (ms)')
    title(['Neural TTL pulses, ' bats_number_name{logger_i}],'Interpreter','none')
    % Check this every time: the differences should start around zero, and
    % change roughly linearly and monotonically to 0.5 or -0.5, which indicates
    % that they would still be rounded to the correct duration, which is fine.
    
    %%
    % Match the neural and audio TTL pulses
    disp('Check figures; press any key to proceed with rounding TTL durations to integer durations...')
    pause
    
    rounded_audio_TTL_durations_ms=round(audio_TTL_durations_ms);
    rounded_neural_TTL_durations_ms=round(neural_TTL_durations_ms);
    
    [logical_indices_audio,indices_neural]=ismembertol(rounded_audio_TTL_durations_ms,rounded_neural_TTL_durations_ms,audio_neural_pulse_match_tolerance_ms,'DataScale',1);
    
    indices_of_shared_pulses_audio=find(logical_indices_audio);
    indices_of_audio_pulses_not_in_neural=find(~logical_indices_audio);
    
    indices_of_shared_pulses_neural=indices_neural(indices_neural~=0);
    indices_of_neural_pulses_not_in_audio=find(~ismember(1:length(rounded_neural_TTL_durations_ms),indices_of_shared_pulses_neural));
    
    if length(indices_of_shared_pulses_audio)<length(audio_fall_times_ms)
        disp(['Deleted ' num2str(length(audio_fall_times_ms)-length(indices_of_shared_pulses_audio)) ' audio pulses that are not present in the neural data...'])
        figure(all_pulses_fig{logger_i})
        subplot(1,2,1)
        hold on
        plot((audio_fall_times_ms(indices_of_audio_pulses_not_in_neural)-audio_fall_times_ms(1))/(1000*60),audio_TTL_durations_ms(indices_of_audio_pulses_not_in_neural),'ro')
    else
        disp('All audio pulses are matched with neural pulses...')
    end
    if length(indices_of_shared_pulses_neural)<length(neural_fall_times_ms)
        disp(['Deleted ' num2str(length(neural_fall_times_ms)-length(indices_of_shared_pulses_neural)) ' neural pulses that are not present in the audio data...'])
        figure(all_pulses_fig{logger_i})
        subplot(1,2,2)
        hold on
        plot((neural_fall_times_ms(indices_of_neural_pulses_not_in_audio)-neural_fall_times_ms(1))/(1000*60),neural_TTL_durations_ms(indices_of_neural_pulses_not_in_audio),'ro')
    else
        disp('All neural pulses are matched with audio pulses...')
    end
    
    audio_sync_times_ms_from_beginning{logger_i}=reshape([audio_fall_times_ms(indices_of_shared_pulses_audio) audio_rise_times_ms(indices_of_shared_pulses_audio)].',[],1);
    neural_sync_with_audio_times_ms_from_midnight{logger_i}=reshape([neural_fall_times_ms(indices_of_shared_pulses_neural) neural_rise_times_ms(indices_of_shared_pulses_neural)].',[],1);
    
    audio_shared_pulse1_time_ms_from_beginning=audio_sync_times_ms_from_beginning{logger_i}(1);
    neural_shared_pulse1_time_ms_from_midnight=neural_sync_with_audio_times_ms_from_midnight{logger_i}(1);
    
    audio_sync_times_ms_from_shared_pulse1=audio_sync_times_ms_from_beginning{logger_i}-audio_shared_pulse1_time_ms_from_beginning;
    neural_sync_times_ms_from_shared_pulse1=neural_sync_with_audio_times_ms_from_midnight{logger_i}-neural_shared_pulse1_time_ms_from_midnight;
    
    figure
    subplot(2,2,1)
    plot(audio_sync_times_ms_from_shared_pulse1/(1000*60),neural_sync_times_ms_from_shared_pulse1/(1000*60),'bo')
    title(['All time points in sync, ' bats_number_name{logger_i}],'Interpreter','none')
    xlabel('Audio time since first shared TTL pulse (minute)')
    ylabel('Neural time since first shared TTL pulse (minute)')
    axis square
    
    subplot(2,2,2)
    plot(audio_sync_times_ms_from_shared_pulse1/(1000*60),audio_sync_times_ms_from_shared_pulse1-neural_sync_times_ms_from_shared_pulse1,'bo')
    xlabel('Audio time since first shared TTL pulse (minute)')
    ylabel('Audio time minus neural time (ms)')
    title('Audio-neural time difference')
    axis tight
    % Should see roughly a straight line starting from 0 and increasing (or
    % decreasing), which results from the audio and neural clocks running at
    % different rates; jumps in the line likely result from the audio or
    % neural system dropping samples or times
    
    subplot(2,2,3)
    plot(diff(audio_sync_times_ms_from_shared_pulse1),'bo')
    xlabel('Shared TTL transition number')
    ylabel('Interval in audio time between consecutive shared transitions (ms)')
    title('Shared TTL transitions - Audio')
    axis tight
    % The increasing straight line at the bottom is the increasing TTL pulse
    % durations; the thick straight line around 5000 ms is the random
    % inter-pulse intervals; the few dots slightly above 5000 ms are likely the
    % intervals between the last pulse of a file and the first pulse of the
    % next file (since each file starts with a TTL-off interval from the usual
    % inter-pulse interval distribution, and each file ends with a fixed
    % interval of TTL-off); the sparse dots above 10000 ms are likely the
    % intervals between the pulse before and pulse after a missed pulse (5000
    % ms x 2, plus the increasing TTL pulse durations)
    
    subplot(2,2,4)
    plot(diff(neural_sync_times_ms_from_shared_pulse1),'bo')
    xlabel('Shared TTL transition number')
    ylabel('Interval in neural time between consecutive shared transitions (ms)')
    title('Shared TTL transitions - Neural')
    axis tight
    
    if logger_i~=length(neural_event_folders)
        disp('Check figures; press any key to process neural data from the next logger...')
        pause
    end
end
disp('Check figures; press any key to proceed with saving sync results...')
pause
%%
clear variables_to_save
variables_to_save.audio_sync_times_ms_from_beginning=audio_sync_times_ms_from_beginning; % for these variables, the ith cell is for the ith bat in "bats_number_name"
variables_to_save.neural_sync_with_audio_times_ms_from_midnight=neural_sync_with_audio_times_ms_from_midnight;
variables_to_save.num_audio_samples_by_end_of_each_file=num_audio_samples_by_end_of_each_file;
variables_to_save.saved_bats_number_name=bats_number_name;
if exist(sync_save_file_name,'file')
    save(sync_save_file_name,'-struct','variables_to_save','-append')
else
    save(sync_save_file_name,'-struct','variables_to_save')
end
disp('Synchronization results saved.')
